{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import findspark \n",
    "import findspark\n",
    "\n",
    "# Initialize and provide path\n",
    "findspark.init(\"/opt/spark/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Linear Regression Model\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile('./Salary_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.1,39343.00', '1.3,46205.00', '1.5,37731.00']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1.1', '39343.00'], ['1.3', '46205.00'], ['1.5', '37731.00']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split lines on commas\n",
    "rdd = rdd.map(lambda line: line.split(\",\"))\n",
    "\n",
    "# Inspect the first line\n",
    "rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.1', '39343.00']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first line \n",
    "rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules \n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Map the RDD to a DF\n",
    "df = rdd.map(lambda line: Row(YearsExperience=line[0], Salary=line[1])).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+\n",
      "|  Salary|YearsExperience|\n",
      "+--------+---------------+\n",
      "|39343.00|            1.1|\n",
      "|46205.00|            1.3|\n",
      "|37731.00|            1.5|\n",
      "|43525.00|            2.0|\n",
      "|39891.00|            2.2|\n",
      "|56642.00|            2.9|\n",
      "|60150.00|            3.0|\n",
      "|54445.00|            3.2|\n",
      "|64445.00|            3.2|\n",
      "|57189.00|            3.7|\n",
      "|63218.00|            3.9|\n",
      "|55794.00|            4.0|\n",
      "|56957.00|            4.0|\n",
      "|57081.00|            4.1|\n",
      "|61111.00|            4.5|\n",
      "|67938.00|            4.9|\n",
      "|66029.00|            5.1|\n",
      "|83088.00|            5.3|\n",
      "|81363.00|            5.9|\n",
      "|93940.00|            6.0|\n",
      "+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the top 20 rows \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Salary: string (nullable = true)\n",
      " |-- YearsExperience: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mostra algumas informações sobre os tipos de dados presentes nas colunas\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all from `sql.types`\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Write a custom function to convert the data type of DataFrame columns\n",
    "def convertColumn(df, names, newType):\n",
    "    for name in names: \n",
    "        df = df.withColumn(name, df[name].cast(newType))\n",
    "    return df \n",
    "\n",
    "# Assign all column names to `columns`\n",
    "columns = ['YearsExperience', 'Salary']\n",
    "\n",
    "# Conver the `df` columns to `FloatType()`\n",
    "df = convertColumn(df, columns, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+\n",
      "| Salary|YearsExperience|\n",
      "+-------+---------------+\n",
      "|39343.0|            1.1|\n",
      "|46205.0|            1.3|\n",
      "|37731.0|            1.5|\n",
      "|43525.0|            2.0|\n",
      "|39891.0|            2.2|\n",
      "|56642.0|            2.9|\n",
      "|60150.0|            3.0|\n",
      "|54445.0|            3.2|\n",
      "|64445.0|            3.2|\n",
      "|57189.0|            3.7|\n",
      "|63218.0|            3.9|\n",
      "|55794.0|            4.0|\n",
      "|56957.0|            4.0|\n",
      "|57081.0|            4.1|\n",
      "|61111.0|            4.5|\n",
      "|67938.0|            4.9|\n",
      "|66029.0|            5.1|\n",
      "|83088.0|            5.3|\n",
      "|81363.0|            5.9|\n",
      "|93940.0|            6.0|\n",
      "+-------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| Salary|\n",
      "+-------+\n",
      "|39343.0|\n",
      "|46205.0|\n",
      "|37731.0|\n",
      "|43525.0|\n",
      "|39891.0|\n",
      "|56642.0|\n",
      "|60150.0|\n",
      "|54445.0|\n",
      "|64445.0|\n",
      "|57189.0|\n",
      "|63218.0|\n",
      "|55794.0|\n",
      "|56957.0|\n",
      "|57081.0|\n",
      "|61111.0|\n",
      "|67938.0|\n",
      "|66029.0|\n",
      "|83088.0|\n",
      "|81363.0|\n",
      "|93940.0|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mostrar apenas uma coluna com o método .select\n",
    "df.select('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|  Salary|count|\n",
      "+--------+-----+\n",
      "|122391.0|    1|\n",
      "|121872.0|    1|\n",
      "|116969.0|    1|\n",
      "|113812.0|    1|\n",
      "|112635.0|    1|\n",
      "|109431.0|    1|\n",
      "|105582.0|    1|\n",
      "|101302.0|    1|\n",
      "| 98273.0|    1|\n",
      "| 93940.0|    1|\n",
      "| 91738.0|    1|\n",
      "| 83088.0|    1|\n",
      "| 81363.0|    1|\n",
      "| 67938.0|    1|\n",
      "| 66029.0|    1|\n",
      "| 64445.0|    1|\n",
      "| 63218.0|    1|\n",
      "| 61111.0|    1|\n",
      "| 60150.0|    1|\n",
      "| 57189.0|    1|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#groupby, onde pode-se agrupar os dados por um determinado pivô. Neste caso, usa-se a coluna Salary como pivô, efetuando a contagem dos valores e ordenando-os em ordem decrescente\n",
    "df.groupBy(\"Salary\").count().sort(\"Salary\",ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
